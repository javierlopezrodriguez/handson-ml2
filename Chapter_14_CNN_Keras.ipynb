{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_14_CNN_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TNiUVtOaYFv"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing ResNet-34 CNN**"
      ],
      "metadata": {
        "id": "9tgKbTQjahby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to avoid repeating, metes la funcion y lo que quieres que sea siempre igual\n",
        "from functools import partial\n",
        "ResConv2D = partial(keras.layers.Conv2D, \n",
        "                    kernel_size = 3, \n",
        "                    padding = \"same\",\n",
        "                    use_bias = False)\n",
        "# al llamarla, le metes los otros argumentos\n",
        "\n",
        "class ResidualUnit(keras.layers.Layer):\n",
        "    def __init__(self, filters, strides = 1, activation = \"relu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = keras.activations.get(activation) # to get the activation function\n",
        "        # las del camino principal:\n",
        "        self.main_layers = [\n",
        "            ResConv2D(filters = filters, strides = strides),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            self.activation,\n",
        "            ResConv2D(filters = filters, strides = 1), # in this case strides = 1 always\n",
        "            keras.layers.BatchNormalization(), # no se acaba en activation, eso lo hacemos despues con la suma de ambas\n",
        "        ]\n",
        "        # las de la skip connection:\n",
        "        self.skip_layers = [] # de normal nada porque los tamaños van a ser =\n",
        "        if strides > 1: # si los tamaños no son =, hay que reducir tambien el del skip connection\n",
        "            self.skip_layers = [\n",
        "                ResConv2D(filters = filters, kernel_size = 1, strides = strides),\n",
        "                keras.layers.BatchNormalization()\n",
        "            ]\n",
        "            # una conv 1x1 con strides = strides para que las dims finales sean =\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # por un lado el camino normal\n",
        "        Z = inputs\n",
        "        for layer in self.main_layers:\n",
        "            Z = layer(Z)\n",
        "        # por otro lado la skip connection\n",
        "        skip_Z = inputs\n",
        "        for layer in self.skip_layers:\n",
        "            skip_Z = layer(skip_Z)\n",
        "        # la suma de ambas\n",
        "        Z_added = Z + skip_Z\n",
        "        # activacion que no estaba en self.main_layers al final\n",
        "        return self.activation(Z_added)\n",
        "\n",
        "    # si quisieramos guardar hiperparams etc habria que hacer el get_config() ..."
      ],
      "metadata": {
        "id": "Rdo7LJVDadaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(filters = 64, kernel_size = 7,\n",
        "                              strides = 2, input_shape = [224, 224, 3],\n",
        "                              padding = \"same\", use_bias = False))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.MaxPool2D(pool_size = 3, strides = 2, padding = \"same\"))\n",
        "\n",
        "# if it is the first one after a change, strides = 2\n",
        "# al duplicar el numero de filters, se reduce las dimensiones con el stride\n",
        "prev_filters = 64\n",
        "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    model.add(ResidualUnit(filters, strides = strides))\n",
        "    prev_filters = filters\n",
        "\n",
        "model.add(keras.layers.GlobalAvgPool2D())\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
      ],
      "metadata": {
        "id": "wAIwd12VhomB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmC30ieziyaq",
        "outputId": "85cc350d-d5aa-4c5c-cfd2-d8390c67dc95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 112, 112, 64)      9408      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 112, 112, 64)     256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 56, 56, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " residual_unit (ResidualUnit  (None, 56, 56, 64)       74240     \n",
            " )                                                               \n",
            "                                                                 \n",
            " residual_unit_1 (ResidualUn  (None, 56, 56, 64)       74240     \n",
            " it)                                                             \n",
            "                                                                 \n",
            " residual_unit_2 (ResidualUn  (None, 56, 56, 64)       74240     \n",
            " it)                                                             \n",
            "                                                                 \n",
            " residual_unit_3 (ResidualUn  (None, 28, 28, 128)      230912    \n",
            " it)                                                             \n",
            "                                                                 \n",
            " residual_unit_4 (ResidualUn  (None, 28, 28, 128)      295936    \n",
            " it)                                                             \n",
            "                                                                 \n",
            " residual_unit_5 (ResidualUn  (None, 28, 28, 128)      295936    \n",
            " it)                                                             \n",
            "                                                                 \n",
            " residual_unit_6 (ResidualUn  (None, 28, 28, 128)      295936    \n",
            " it)                                                             \n",
            "                                                                 \n",
            " residual_unit_7 (ResidualUn  (None, 14, 14, 256)      920576    \n",
            " it)                                                             \n",
            "                                                                 \n",
            " residual_unit_8 (ResidualUn  (None, 14, 14, 256)      1181696   \n",
            " it)                                                             \n",
            "                                                                 \n",
            " residual_unit_9 (ResidualUn  (None, 14, 14, 256)      1181696   \n",
            " it)                                                             \n",
            "                                                                 \n",
            " residual_unit_10 (ResidualU  (None, 14, 14, 256)      1181696   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_11 (ResidualU  (None, 14, 14, 256)      1181696   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_12 (ResidualU  (None, 14, 14, 256)      1181696   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_13 (ResidualU  (None, 7, 7, 512)        3676160   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_14 (ResidualU  (None, 7, 7, 512)        4722688   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " residual_unit_15 (ResidualU  (None, 7, 7, 512)        4722688   \n",
            " nit)                                                            \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,306,826\n",
            "Trainable params: 21,289,802\n",
            "Non-trainable params: 17,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XKI7M5Hgizm0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}